{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f9409a",
   "metadata": {},
   "source": [
    "### Import Libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "63e85355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import os, glob, json, random, math\n",
    "import numpy as np\n",
    "import pydicom, cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9de075",
   "metadata": {},
   "source": [
    "### Load Image Dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c82d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads a single dicom image and converts it to a numpy array\n",
    "def load_dicom_image(file_path):\n",
    "    \"\"\"Load a DICOM image and return it as a numpy array.\"\"\"\n",
    "    dicom = pydicom.dcmread(file_path)\n",
    "    image = dicom.pixel_array\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image, target_size=(256, 256)):\n",
    "    \"\"\"Preprocess the image: resize and normalize.\"\"\"\n",
    "    image_resized = cv2.resize(image, target_size)\n",
    "    image_normalized = (image_resized - np.min(image_resized)) / (np.max(image_resized) - np.min(image_resized))\n",
    "    return image_normalized\n",
    "\n",
    "# reads all dicom images from a directory and preprocesses them\n",
    "def load_dicom_images_from_directory(directory):\n",
    "    \"\"\"Load and preprocess all DICOM images from a directory.\"\"\"\n",
    "    file_paths = glob(os.path.join(directory, '*.dcm'))\n",
    "    images = []\n",
    "    for file_path in file_paths:\n",
    "        image = load_dicom_image(file_path)\n",
    "        image_preprocessed = preprocess_image(image)\n",
    "        images.append(image_preprocessed)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fcc249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: ID00184637202242062969203\n",
      "Found 62 DICOM slices\n"
     ]
    }
   ],
   "source": [
    "# testing the functions (IGNORE THIS)\n",
    "\n",
    "dicom_files = glob(os.path.join('path_to_dicom_files', '*.dcm'))\n",
    "for file in dicom_files:\n",
    "    img = load_dicom_image(file)\n",
    "    img_preprocessed = preprocess_image(img)\n",
    "    print(f\"Processed image shape: {img_preprocessed.shape}\")\n",
    "    break  # Just process one file for demonstration\n",
    "\n",
    "# --- PATH TO YOUR DATA ---\n",
    "root_folder = \"/Users/jinkyungjeon/cs3244_project/osic-pulmonary-fibrosis-progression/train\"\n",
    "\n",
    "# Choose one patient\n",
    "patient_id = \"ID00184637202242062969203\"  # change this to any patient folder name\n",
    "patient_folder = os.path.join(root_folder, patient_id)\n",
    "\n",
    "# Get all DICOM file paths in that patient's folder\n",
    "dicom_files = sorted([os.path.join(patient_folder, f) for f in os.listdir(patient_folder) if f.endswith(\".dcm\")])\n",
    "\n",
    "print(f\"Patient: {patient_id}\")\n",
    "print(f\"Found {len(dicom_files)} DICOM slices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929ceb1",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd8c81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pydicom, numpy as np, cv2, random, json\n",
    "from typing import List, Dict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "def dicom_to_hu(path: str) -> np.ndarray:\n",
    "    \"\"\"Convert DICOM pixel data to Hounsfield Units (HU).\"\"\"\n",
    "    dicom = pydicom.dcmread(path)\n",
    "    image = dicom.pixel_array.astype(np.int16)\n",
    "\n",
    "    # Convert to HU\n",
    "    intercept = dicom.RescaleIntercept\n",
    "    slope = dicom.RescaleSlope \n",
    "\n",
    "    image = slope * image + intercept\n",
    "\n",
    "    return image\n",
    "\n",
    "def lung_window(img_hu: np.ndarray, center = -600, width = 1500) -> np.ndarray:\n",
    "    \"\"\"Apply lung windowing to the HU image.\"\"\"\n",
    "\n",
    "    min_hu = center - (width // 2)\n",
    "    max_hu = center + (width // 2)\n",
    "\n",
    "    img_windowed = np.clip(img_hu, min_hu, max_hu) \n",
    "\n",
    "    return img_windowed\n",
    "\n",
    "def load_patient_stack(dicom_dir: str, target_depth: int = 96, img_size: int = 224) -> np.ndarray:\n",
    "    \"\"\"Load all slices, sort by InstanceNumber, window, resize, depth-pad/trim.\"\"\"\n",
    "    files = glob.glob(os.path.join(dicom_dir, \"*.dcm\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No DICOMs in {dicom_dir}\")\n",
    "\n",
    "    # sort slices using InstanceNumber or filename fallback\n",
    "    def inst_no(fp):\n",
    "        try:\n",
    "            return int(pydicom.dcmread(fp, stop_before_pixels=True).InstanceNumber)\n",
    "        except Exception:\n",
    "            return 0\n",
    "    files.sort(key=inst_no)\n",
    "\n",
    "    slices = [lung_window(dicom_to_hu(fp)) for fp in files] # apply lung windowing to each slice converted to HU\n",
    "\n",
    "    # resize each slice to cnn standard image size\n",
    "    slices = [cv2.resize(s, (img_size, img_size), interpolation=cv2.INTER_AREA) for s in slices]\n",
    "    vol = np.stack(slices, axis=0)  # [D, H, W]\n",
    "\n",
    "    # normalize per-volume (optional but helpful)\n",
    "    v = vol.astype(np.float32)\n",
    "    v = (v - v.mean()) / (v.std() + 1e-6)\n",
    "\n",
    "    # depth pad/trim to target_depth\n",
    "    D = v.shape[0]\n",
    "    if D == target_depth:\n",
    "        pass\n",
    "    elif D > target_depth:\n",
    "        # uniform downsample to target_depth\n",
    "        idx = np.linspace(0, D-1, target_depth).round().astype(int)\n",
    "        v = v[idx]\n",
    "    else:\n",
    "        # pad by symmetric reflection\n",
    "        pad_needed = target_depth - D\n",
    "        pre = pad_needed // 2\n",
    "        post = pad_needed - pre\n",
    "        v = np.pad(v, ((pre, post), (0,0), (0,0)), mode=\"reflect\")\n",
    "\n",
    "    # channel-first for 2D CNN over slices: keep as [D, H, W]; we’ll add channel later\n",
    "    return v  # float32\n",
    "\n",
    "class OSICMini(Dataset):\n",
    "    def __init__(self, rows: List[Dict], depth=96, size=224, aug=False):\n",
    "        self.rows = rows; self.depth = depth; self.size = size; self.aug = aug\n",
    "\n",
    "    def __len__(self): return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        r = self.rows[i]\n",
    "        vol = load_stack(r[\"dicom_dir\"], self.depth, self.size)  # [D,H,W]\n",
    "        # simple flips\n",
    "        if self.aug:\n",
    "            if random.random() < 0.5: vol = np.flip(vol, 1).copy()\n",
    "            if random.random() < 0.5: vol = np.flip(vol, 2).copy()\n",
    "        x = torch.from_numpy(vol)[None, ...]  # [1,D,H,W]\n",
    "        y = torch.tensor(float(r[\"fvc\"]), dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "def make_loader(rows, batch_size=2, shuffle=True, num_workers=4, **kw):\n",
    "    ds = OSICMini(rows, **kw)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n",
    "                      num_workers=num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b7281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819e2844",
   "metadata": {},
   "source": [
    "### Model: Basic CNN architecture (slice encoder) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6826b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicSliceCNN(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(256, out_dim)\n",
    "\n",
    "    def forward(self, x):  # [B*D,1,H,W]\n",
    "        f = self.conv(x).flatten(1)\n",
    "        return self.fc(f)\n",
    "\n",
    "class DepthAggregator(nn.Module):\n",
    "    def __init__(self, in_dim=256, hidden=256):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_dim, hidden, kernel_size=5, padding=2)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc  = nn.Linear(hidden, hidden)\n",
    "\n",
    "    def forward(self, feat_seq):\n",
    "        x = feat_seq.transpose(1, 2)\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.gap(x).squeeze(-1)\n",
    "        return F.relu(self.fc(x))\n",
    "\n",
    "class GaussianHead(nn.Module):\n",
    "    def __init__(self, in_dim=256):\n",
    "        super().__init__()\n",
    "        self.mu = nn.Linear(in_dim, 1)\n",
    "        self.log_var = nn.Linear(in_dim, 1)\n",
    "    def forward(self, x):\n",
    "        mu = self.mu(x).squeeze(1)\n",
    "        log_var = self.log_var(x).squeeze(1)\n",
    "        log_var = torch.clamp(log_var, -5.0, 5.0)\n",
    "        return mu, log_var\n",
    "\n",
    "class OSICProbCNN(nn.Module):\n",
    "    def __init__(self, slice_dim=256, agg_dim=256):\n",
    "        super().__init__()\n",
    "        self.encoder = BasicSliceCNN(in_ch=1, out_dim=slice_dim)\n",
    "        self.agg = DepthAggregator(in_dim=slice_dim, hidden=agg_dim)\n",
    "        self.head = GaussianHead(in_dim=agg_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B,C,D,H,W = x.shape\n",
    "        x = x.permute(0,2,1,3,4).contiguous()\n",
    "        x = x.view(B*D,1,H,W)\n",
    "        feats = self.encoder(x)\n",
    "        feats = feats.view(B,D,-1)\n",
    "        g = self.agg(feats)\n",
    "        mu, log_var = self.head(g)\n",
    "        return mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e06d7a",
   "metadata": {},
   "source": [
    "### LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "420f558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GaussianNLL(nn.Module):\n",
    "    def forward(self, mu, log_var, y):\n",
    "        inv_var = torch.exp(-log_var)\n",
    "        nll = 0.5 * ((y - mu)**2 * inv_var + log_var + math.log(2*math.pi))\n",
    "        return nll.mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def gaussian_crps(mu, sigma, y):\n",
    "    from torch.distributions.normal import Normal\n",
    "    eps = 1e-7\n",
    "    sigma = torch.clamp(sigma, min=eps)\n",
    "    z = (y - mu) / sigma\n",
    "    normal0 = Normal(torch.zeros_like(z), torch.ones_like(z))\n",
    "    pdf = torch.exp(normal0.log_prob(z))\n",
    "    cdf = normal0.cdf(z)\n",
    "    return (sigma * (z*(2*cdf - 1) + 2*pdf - 1/math.sqrt(math.pi))).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def gaussian_quantiles(mu, sigma, qs=(0.05,0.5,0.95)):\n",
    "    z = {0.05:-1.6449, 0.5:0.0, 0.95:1.6449}\n",
    "    return [mu + sigma*z[q] for q in qs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c5b18",
   "metadata": {},
   "source": [
    "### Dataset Loader ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b76ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_hu(fp):\n",
    "    d = pydicom.dcmread(fp)\n",
    "    arr = d.pixel_array.astype(np.int16)\n",
    "    slope = float(getattr(d, \"RescaleSlope\", 1.0))\n",
    "    intercept = float(getattr(d, \"RescaleIntercept\", 0.0))\n",
    "    return arr * slope + intercept\n",
    "\n",
    "def _window_norm(img_hu, center=-600, width=1500):\n",
    "    low, high = center - width/2, center + width/2\n",
    "    img = np.clip(img_hu, low, high)\n",
    "    return (img - low) / (high - low + 1e-6)\n",
    "\n",
    "def _slice_key(fp):\n",
    "    try: return int(pydicom.dcmread(fp, stop_before_pixels=True).InstanceNumber)\n",
    "    except: return 0\n",
    "\n",
    "def load_stack(dicom_dir, target_depth=96, img_size=224):\n",
    "    fps = sorted(glob.glob(os.path.join(dicom_dir, \"*.dcm\")), key=_slice_key)\n",
    "    slices = [_window_norm(_read_hu(fp)) for fp in fps]\n",
    "    slices = [cv2.resize(s, (img_size, img_size)) for s in slices]\n",
    "    vol = np.stack(slices, axis=0).astype(np.float32)\n",
    "    vol = (vol - vol.mean()) / (vol.std() + 1e-6)\n",
    "    D = vol.shape[0]\n",
    "    if D > target_depth:\n",
    "        idx = np.linspace(0, D-1, target_depth).round().astype(int)\n",
    "        vol = vol[idx]\n",
    "    elif D < target_depth:\n",
    "        pad = target_depth - D\n",
    "        pre = pad // 2; post = pad - pre\n",
    "        vol = np.pad(vol, ((pre, post), (0,0), (0,0)), mode=\"reflect\")\n",
    "    return vol\n",
    "\n",
    "class OSICDataset(Dataset):\n",
    "    def __init__(self, rows, depth=96, size=224, aug=False):\n",
    "        self.rows = rows; self.depth = depth; self.size = size; self.aug = aug\n",
    "    def __len__(self): return len(self.rows)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.rows[i]\n",
    "        vol = load_stack(r[\"dicom_dir\"], self.depth, self.size)\n",
    "        if self.aug:\n",
    "            if random.random() < 0.5: vol = np.flip(vol, 1).copy()\n",
    "            if random.random() < 0.5: vol = np.flip(vol, 2).copy()\n",
    "        x = torch.from_numpy(vol)[None, ...]  # [1,D,H,W]\n",
    "        y = torch.tensor(float(r[\"fvc\"]), dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "def make_loader(rows, batch_size=2, shuffle=True, num_workers=2, **kw):\n",
    "    ds = OSICDataset(rows, **kw)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494d426",
   "metadata": {},
   "source": [
    "### Train / Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4254fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, opt, loss_fn, device, scaler=None, clip=1.0):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        if scaler:\n",
    "            with autocast():\n",
    "                mu, log_var = model(x)\n",
    "                loss = loss_fn(mu, log_var, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            scaler.step(opt); scaler.update()\n",
    "        else:\n",
    "            mu, log_var = model(x)\n",
    "            loss = loss_fn(mu, log_var, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "        total += loss.item() * x.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    nlls, crpss = [], []\n",
    "    cover90, total = 0, 0\n",
    "    nll_fn = GaussianNLL()\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        mu, log_var = model(x)\n",
    "        nll = nll_fn(mu, log_var, y).item()\n",
    "        sigma = torch.sqrt(torch.exp(log_var))\n",
    "        crps = gaussian_crps(mu, sigma, y).item()\n",
    "        q05, q50, q95 = gaussian_quantiles(mu, sigma)\n",
    "        inside = ((y >= q05) & (y <= q95)).float().sum().item()\n",
    "        cover90 += inside; total += y.numel()\n",
    "        nlls.append(nll); crpss.append(crps)\n",
    "    return {\"NLL\": np.mean(nlls), \"CRPS\": np.mean(crpss), \"PI90\": cover90/total}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "397e45fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
      "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
      "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
      "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
      "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
      "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker\n",
      "Total patients found: 176\n"
     ]
    }
   ],
   "source": [
    "import os, glob, pandas as pd, numpy as np, torch, cv2, pydicom, random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# paths\n",
    "DATA_DIR = \"/Users/jinkyungjeon/cs3244_project/osic-pulmonary-fibrosis-progression\" # root folder containing train/ and test/\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "\n",
    "# read CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.head())\n",
    "\n",
    "# each patient folder is DATA_DIR/train/<PatientID>/\n",
    "# we’ll just use the \"FVC\" from train.csv as labels\n",
    "patient_dirs = {p: os.path.join(DATA_DIR, \"train\", p) for p in os.listdir(os.path.join(DATA_DIR, \"train\"))}\n",
    "\n",
    "# merge csv + directory path\n",
    "df[\"dicom_dir\"] = df[\"Patient\"].map(patient_dirs)\n",
    "# keep only existing folders\n",
    "df = df[df[\"dicom_dir\"].apply(os.path.isdir)].reset_index(drop=True)\n",
    "\n",
    "# make sure we only keep one FVC per patient (baseline)\n",
    "df = df.groupby(\"Patient\").first().reset_index()\n",
    "\n",
    "print(f\"Total patients found: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a0460383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train patients: 141, Val patients: 35\n"
     ]
    }
   ],
   "source": [
    "train_df = df.sample(frac=0.8, random_state=42)  # 80% train\n",
    "val_df   = df.drop(train_df.index)               # 20% val\n",
    "\n",
    "train_loader = DataLoader(OSICDataset(train_df), batch_size=2, shuffle=True)\n",
    "val_loader   = DataLoader(OSICDataset(val_df),   batch_size=2, shuffle=False)\n",
    "print(f\"Train patients: {len(train_df)}, Val patients: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "354dfb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/bk/6nc34r7d5d32rbmm3kk61g6w0000gn/T/ipykernel_3745/2436056553.py\", line 4, in <module>\n",
      "    opt =  torch.optim.Adam(model.parameters(), lr=1e-3)\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/optim/adam.py\", line 99, in __init__\n",
      "    fused = group.setdefault(\"fused\", None)\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 377, in __init__\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_compile.py\", line 27, in inner\n",
      "    import torch._dynamo\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
      "    from . import convert_frame, eval_frame, resume_execution\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py\", line 53, in <module>\n",
      "    from . import config, exc, trace_rules\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/trace_rules.py\", line 46, in <module>\n",
      "    from .variables import (\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/variables/__init__.py\", line 2, in <module>\n",
      "    from .builtin import BuiltinVariable\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/variables/builtin.py\", line 47, in <module>\n",
      "    from .ctx_manager import EventVariable, StreamVariable\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/variables/ctx_manager.py\", line 17, in <module>\n",
      "    from ..device_interface import get_interface_for_device\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/device_interface.py\", line 154, in <module>\n",
      "    class CudaInterface(DeviceInterface):\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/torch/_dynamo/device_interface.py\", line 26, in __new__\n",
      "    assert inspect.isclass(class_member[\"Event\"]) and issubclass(\n",
      "AssertionError: DeviceInterface member Event should be inherit from _EventBase\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "model = OSICProbCNN()          # your CNN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "opt =  torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# loss_fn = GaussianNLL()\n",
    "\n",
    "# for epoch in range(1, 6):      # e.g. train 5 epochs\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for x, y in train_loader:\n",
    "#         opt.zero_grad()\n",
    "#         mu, log_var = model(x)\n",
    "#         loss = loss_fn(mu, log_var, y)\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         total_loss += loss.item() * x.size(0)\n",
    "\n",
    "#     avg_train = total_loss / len(train_loader.dataset)\n",
    "\n",
    "#     # simple validation (no device, no AMP)\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in val_loader:\n",
    "#             mu, log_var = model(x)\n",
    "#             val_loss += loss_fn(mu, log_var, y).item() * x.size(0)\n",
    "#     avg_val = val_loss / len(val_loader.dataset)\n",
    "\n",
    "#     print(f\"Epoch {epoch}: Train {avg_train:.4f} | Val {avg_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca26b45",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/Users/jinkyungjeon/cs3244_project/osic-pulmonary-fibrosis-progression\"\n",
    "train_csv = pd.read_csv(os.path.join(dir, 'train.csv'))\n",
    "train_path = os.path.join(dir, 'train')\n",
    "\n",
    "train_path = os.path.join(dir, 'train')\n",
    "test_path = os.path.join(dir, 'test')\n",
    "\n",
    "train_patients = [d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))]\n",
    "test_patients = [d for d in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, d))]\n",
    "\n",
    "print(len(train_patients), len(test_patients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46896641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients in the training tabular file \n",
    "train_csv = pd.read_csv(os.path.join(dir, 'train.csv'))\n",
    "print(len(train_csv)) # prints the number of rows in the CSV file\n",
    "\n",
    "# Number of patients in the training ct scan folder\n",
    "train_patients = [d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))]\n",
    "print(len(train_patients)) # prints the number of patient folders in the training folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f597a5",
   "metadata": {},
   "source": [
    "### Simple CNN Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341bbc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.4 when it was built against 1.14.3, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_cnn(input_shape=(224,224,1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, activation='linear')(x)\n",
    "    return models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ef241",
   "metadata": {},
   "source": [
    "### Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0cac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cs3244/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_train = load_dicom_images_from_directory(os.path.join(train_path, patient_id))\n",
    "y_train = train_csv[train_csv['Patient'] == patient_id]['FVC'].values\n",
    "\n",
    "X_test = load_dicom_images_from_directory(os.path.join(test_path, patient_id))\n",
    "y_test = train_csv[train_csv['Patient'] == patient_id]['FVC'].values\n",
    "\n",
    "# Build CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(256,256,1)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1, activation='linear')  # regression for FVC\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n",
    "\n",
    "# Suppose X_train and y_train are ready\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs3244",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
