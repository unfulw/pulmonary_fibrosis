{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416821a0",
   "metadata": {},
   "source": [
    "For the tabular portion of the multimodal probabilistic model fusion, Gaussian Process is used, as it is particularly effective in capturing trends in time-series data, even with a small and irregular dataset. Gaussian Process is a stochastic learning method that learns the transition probability in a continuous time-scale by conditioning each discrete time-series data point with interpolated time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b78aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.kernels import ScaleKernel, MaternKernel, RBFKernel, IndexKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3de379",
   "metadata": {},
   "source": [
    "For train-test split, it is done by unique patient IDs, as each row in the CSV is not a unique entry, but a series of rows for each patient ID is. Thus, the corresponding y (outcome) only is the FVC value in the last recorded week for each patient. \n",
    "\n",
    "Then, numerical features are normalized to ensure their equal weightage, followed by conversion to pyTorch tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ba008f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path().resolve()\n",
    "csv_path = BASE_DIR.parent / \"data\" / \"train.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path).drop(columns = [\"Percent\"])\n",
    "\n",
    "ids = df['Patient'].unique()\n",
    "train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=3244)\n",
    "\n",
    "train_df = df[df['Patient'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df   = df[df['Patient'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "time_scaler = StandardScaler()\n",
    "fvc_scaler = StandardScaler()\n",
    "train_df[\"Weeks_scaled\"] = time_scaler.fit_transform(train_df[[\"Weeks\"]])\n",
    "train_df[\"FVC_scaled\"] = fvc_scaler.fit_transform(train_df[[\"FVC\"]])\n",
    "val_df[\"Weeks_scaled\"] = time_scaler.transform(val_df[[\"Weeks\"]])\n",
    "val_df[\"FVC_scaled\"] = fvc_scaler.transform(val_df[[\"FVC\"]])\n",
    "train_df = train_df.sort_values([\"Patient\", \"Weeks\"]).reset_index(drop=True)\n",
    "\n",
    "#tidying validation dataframe (collapsing rows)\n",
    "first_week = val_df.loc[val_df.groupby(\"Patient\")[\"Weeks\"].idxmin(), [\"Patient\", \"Age\", \"Sex\", \"SmokingStatus\", \"Weeks_scaled\", \"FVC_scaled\"]]\n",
    "last_week  = val_df.loc[val_df.groupby(\"Patient\")[\"Weeks\"].idxmax(), [\"Patient\", \"Weeks_scaled\"]]\n",
    "first_week = first_week.sort_values(\"Patient\").reset_index(drop=True)\n",
    "last_week  = last_week.sort_values(\"Patient\").reset_index(drop=True)\n",
    "dweek = last_week[\"Weeks_scaled\"].values - first_week[\"Weeks_scaled\"].values\n",
    "\n",
    "val_df = val_df.loc[val_df.groupby(\"Patient\")[\"Weeks_scaled\"].idxmin(), [\"Patient\", \"Age\", \"Sex\", \"SmokingStatus\", \"Weeks_scaled\", \"FVC_scaled\"]]\n",
    "val_df[\"Weeks_scaled\"] = dweek\n",
    "val_df = val_df.sort_values([\"Patient\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59d5dc",
   "metadata": {},
   "source": [
    "Now that the preprocessing is complete, model is built with separate kernels for the time series, and each categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1191ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal: True shape: torch.Size([1234, 1]) torch.Size([1234, 1]) dtype: torch.float32 torch.float32 device: cpu cpu\n",
      "equal: True shape: torch.Size([1234, 1]) torch.Size([1234, 1]) dtype: torch.float32 torch.float32 device: cpu cpu\n",
      "equal: True shape: torch.Size([1234, 1]) torch.Size([1234, 1]) dtype: torch.int64 torch.int64 device: cpu cpu\n",
      "equal: True shape: torch.Size([1234, 1]) torch.Size([1234, 1]) dtype: torch.int64 torch.int64 device: cpu cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m200\u001b[39m):  \n\u001b[32m     61\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     loss = -mll(output, y_train)\n\u001b[32m     64\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rlaal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gpytorch\\models\\exact_gp.py:280\u001b[39m, in \u001b[36mExactGP.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    277\u001b[39m             torch.equal(train_input, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m train_input, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m length_safe_zip(train_inputs, inputs)\n\u001b[32m    278\u001b[39m         ):\n\u001b[32m    279\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou must train on the training inputs!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     res = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# Prior mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rlaal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gpytorch\\module.py:82\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *inputs, **kwargs) -> Union[Tensor, Distribution, LinearOperator]:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     84\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mExactGPModel.forward\u001b[39m\u001b[34m(self, Xt, Xage, Xsex, Xsmk)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, Xt, Xage, Xsex, Xsmk):\n\u001b[32m     46\u001b[39m     mean = \u001b[38;5;28mself\u001b[39m.mean_module(torch.cat([Xt, Xage], dim=-\u001b[32m1\u001b[39m)) \n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     covar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcovar_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXsex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXsmk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gpytorch.distributions.MultivariateNormal(mean, covar)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rlaal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gpytorch\\kernels\\kernel.py:488\u001b[39m, in \u001b[36mKernel.__call__\u001b[39m\u001b[34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    460\u001b[39m     \u001b[38;5;28mself\u001b[39m, x1: Tensor, x2: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m, diag: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, last_dim_is_batch: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, **params\n\u001b[32m    461\u001b[39m ) -> Union[LazyEvaluatedKernelTensor, LinearOperator, Tensor]:\n\u001b[32m    462\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m    Computes the covariance between :math:`\\mathbf x_1` and :math:`\\mathbf x_2`.\u001b[39;00m\n\u001b[32m    464\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    486\u001b[39m \u001b[33;03m        * `diag` with `last_dim_is_batch=True`: `... x K x N`\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m last_dim_is_batch:\n\u001b[32m    489\u001b[39m         warnings.warn(\n\u001b[32m    490\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe last_dim_is_batch argument is deprecated, and will be removed in GPyTorch 2.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf you are using it as part of AdditiveStructureKernel or ProductStructureKernel, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    494\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    495\u001b[39m         )\n\u001b[32m    497\u001b[39m     x1_, x2_ = x1, x2\n",
      "\u001b[31mRuntimeError\u001b[39m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "X_time_train = torch.tensor(train_df[[\"Weeks_scaled\"]].values, dtype=torch.float32)\n",
    "X_age_train = torch.tensor(train_df[[\"Age\"]].values, dtype=torch.float32)\n",
    "\n",
    "sex_map = {k:i for i,k in enumerate(train_df[\"Sex\"].astype(\"category\").cat.categories)}\n",
    "smk_map = {k:i for i,k in enumerate(train_df[\"SmokingStatus\"].astype(\"category\").cat.categories)}\n",
    "sex_train = torch.tensor(train_df[\"Sex\"].map(sex_map).values, dtype=torch.long).unsqueeze(-1)\n",
    "smk_train = torch.tensor(train_df[\"SmokingStatus\"].map(smk_map).values, dtype=torch.long).unsqueeze(-1)\n",
    "\n",
    "y_train = torch.tensor(train_df[\"FVC_scaled\"].values, dtype=torch.float32)\n",
    "\n",
    "class MixedKernel(gpytorch.kernels.Kernel):\n",
    "    has_lengthscale = False\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5))\n",
    "        self.age  = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "        self.sex  = gpytorch.kernels.IndexKernel(num_tasks=len(sex_map), rank=2)\n",
    "        self.smk  = gpytorch.kernels.IndexKernel(num_tasks=len(smk_map), rank=2)\n",
    "\n",
    "        self.register_parameter(name=\"raw_bias\", parameter=torch.nn.Parameter(torch.tensor(0.0)))\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return torch.nn.functional.softplus(self.raw_bias)\n",
    "\n",
    "    def forward(self, x_time, x_age, x_sex, x_smk, diag=False, **params):\n",
    "        Kt = self.time(x_time, x_time, diag=diag)\n",
    "        Ka = self.age(x_age,  x_age,  diag=diag)\n",
    "\n",
    "        Ks  = self.sex(x_sex.squeeze(-1),  x_sex.squeeze(-1))\n",
    "        Km  = self.smk(x_smk.squeeze(-1),  x_smk.squeeze(-1))\n",
    "\n",
    "        Kdemo = Ka + Ks + Km\n",
    "\n",
    "        return Kt * Kdemo \n",
    "    \n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, Xt, Xage, Xsex, Xsmk, y, likelihood):\n",
    "        super().__init__(train_inputs=(Xt, Xage, Xsex, Xsmk), train_targets=y, likelihood=likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = MixedKernel()\n",
    "\n",
    "    def forward(self, Xt, Xage, Xsex, Xsmk):\n",
    "        mean = self.mean_module(torch.cat([Xt, Xage], dim=-1)) \n",
    "        covar = self.covar_module(Xt, Xage, Xsex, Xsmk)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)\n",
    "\n",
    "likelihood = GaussianLikelihood()\n",
    "model = ExactGPModel(X_time_train, X_age_train, sex_train, smk_train, y_train, likelihood)\n",
    "\n",
    "model.train(); likelihood.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for a, b in zip(model.train_inputs, (X_time_train, X_age_train, sex_train, smk_train)):\n",
    "    print(\"equal:\", torch.equal(a, b), \"shape:\", a.shape, b.shape, \"dtype:\", a.dtype, b.dtype, \"device:\", a.device, b.device)\n",
    "\n",
    "for i in range(200):  \n",
    "    optimizer.zero_grad()\n",
    "    output = model(*model.train_inputs)\n",
    "    loss = -mll(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "model.eval(); likelihood.eval()\n",
    "\n",
    "Xc_val  = torch.tensor(val_df[[\"Weeks_scaled\",\"Age\"]].values, dtype=torch.float32)\n",
    "sex_val = torch.tensor(val_df[\"Sex\"].map(sex_map).values, dtype=torch.long).unsqueeze(-1)\n",
    "smk_val = torch.tensor(val_df[\"SmokingStatus\"].map(smk_map).values, dtype=torch.long).unsqueeze(-1)\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    X_time_val = torch.tensor(val_df[[\"Weeks_scaled\"]].values, dtype=torch.float32)\n",
    "    X_age_val  = torch.tensor(val_df[[\"Age\"]].values,          dtype=torch.float32)\n",
    "    pred = likelihood(model(X_time_val, X_age_val, sex_val, smk_val))   \n",
    "    y_mean = pred.mean.numpy()\n",
    "    y_std  = pred.variance.sqrt().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
